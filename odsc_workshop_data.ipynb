{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Dataset optimization for training on the Cloud\n",
    "\n",
    "### Why is training on the Cloud different?\n",
    "1. Files are remote, which requires downloading (slow)\n",
    "2. Cloud services have rate-limits on how many files can be downloaded per second (~1.5k / sec / file prefix)\n",
    "3. Very large dataset's might not fit on disk\n",
    "\n",
    "### What can we do about it?\n",
    "We want to minimize the number of file transfers.\n",
    "To do that we need to store the data in a format that's optimized\n",
    "1. Storing the data compressed\n",
    "2. Group files\n",
    "\n",
    "This would reduce:\n",
    "* the amount of files required to be downloaded\n",
    "* time to download the data\n",
    "* risk of rate-limiting\n",
    "* amount of data needed in memory per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = <your path>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageNet 1M dataset contains 1,431,167 labeled images according to the WordNet hierarchy and has been used a reference dataset for compute vision for many years.\n",
    "\n",
    "Total number of images:\n",
    "* Train: 1,281,167\n",
    "* Validation: 50,000\n",
    "* Test: 100,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Lightning-AI/lightning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!cd lightning && git checkout fd48627303386a342e5252098ad7fb0d48a14cb8 && pip install -e .\n",
    "! pip install -U torch lightning-cloud matplotlib torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the ImageNet dataset for training\n",
    "with `DatasetOptimizer` and `StreamingDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import LightningDataModule\n",
    "from lightning.data import StreamingDataset, StreamingDataLoader, DatasetOptimizer\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from imagenet_utils import get_class_index_from_filepath, to_rgb, shuffle, load_imagenet_val_class_names, class_names_to_index_map\n",
    "from lightning.data.streaming.dataset import StreamingDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetStreamingDataset(StreamingDataset):\n",
    "\n",
    "    def __init__(self, name, version):\n",
    "        super().__init__(name=name, version=version)\n",
    "        self.transform = T.Compose([\n",
    "            T.RandomResizedCrop((224, 224), antialias=True),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Note: If torchvision is installed, we return a tensor image instead of a pil image as it is much faster. \n",
    "        img, class_index = super().__getitem__(index) # <- Whatever you returned from the DatasetOptimizer prepare_item method.\n",
    "        return self.transform(to_rgb(img) / 255.), int(class_index)   \n",
    "\n",
    "\n",
    "class ImageNetCloudDataModule(LightningDataModule):\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_dataset_structure(root, image_paths):\n",
    "        if \"train\" in root:\n",
    "            class_indexes = [get_class_index_from_filepath(image_path) for image_path in image_paths]\n",
    "            items_metadata = [(image_path, class_index) for image_path, class_index in zip(image_paths, class_indexes)]\n",
    "            return shuffle(items_metadata)\n",
    "        else:\n",
    "            class_names = load_imagenet_val_class_names()\n",
    "            return [(image_path, class_names_to_index_map[class_name]) for image_path, class_name in zip(image_paths, class_names)]\n",
    "            \n",
    "    @staticmethod\n",
    "    def prepare_item(item_metadata):\n",
    "        image_path, class_index = item_metadata\n",
    "        return [Image.open(image_path), class_index] # <- What you return here is what you get in the StreamingDataset\n",
    "    \n",
    "    @property\n",
    "    def train_dataset(self):\n",
    "        return ImageNetStreamingDataset(name=\"imagenet/train\", version=\"latest\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=256, num_workers=os.cpu_count(), pin_memory=True)\n",
    "\n",
    "    @property\n",
    "    def val_dataset(self):\n",
    "        return ImageNetStreamingDataset(name=\"imagenet/val\", version=\"latest\")\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=256, num_workers=os.cpu_count(), pin_memory=True)\n",
    "\n",
    "\n",
    "data_module = ImageNetCloudDataModule()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify before processing the entire dataset\n",
    "We run the `DatasetOptimizer` in `fast_dev_run=True` mode to verify everything works fine.\n",
    "\n",
    "Listing files the first time is slow but it get cached. It should take roughtly 5 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!sudo rm -r /cache/data /cache/imagenet\n",
    "! rm -rf ~/.cache/imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the shards\n",
    "dataset_optimizer = DatasetOptimizer(\n",
    "    name=\"imagenet/train\",\n",
    "    src_dir=f\"{s3_path}/train\",\n",
    "    fast_dev_run=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "dataset_optimizer.run(data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_optimizer = DatasetOptimizer(\n",
    "    name=\"imagenet/val\",\n",
    "    src_dir=f\"{s3_path}/val\",\n",
    "    fast_dev_run=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "dataset_optimizer.run(data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.data.streaming.dataset import StreamingDataset\n",
    "\n",
    "train_dataset = data_module.train_dataset\n",
    "\n",
    "print(f\"Number of samples: {len(train_dataset)}\")\n",
    "print(f\"First element: {train_dataset[0]}\")\n",
    "\n",
    "image, target = train_dataset[0]\n",
    "plt.imshow(T.ToPILImage()(image), interpolation=\"bicubic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch \n",
    "from torchmetrics import Accuracy\n",
    "import torch.nn.functional as F\n",
    "from torch import inference_mode\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1).to(device)\n",
    "model.eval()\n",
    "acc_metric = Accuracy(task=\"multiclass\", num_classes=1000, top_k=5).to(device)\n",
    "\n",
    "dataloader = data_module.train_dataloader()\n",
    "\n",
    "with inference_mode():\n",
    "    for batch in tqdm(dataloader, smoothing=0):\n",
    "        images, target = batch\n",
    "        images = images.to(device).float()\n",
    "        target = target.to(device)\n",
    "        output = model(images)\n",
    "        acc = acc_metric(output, target)\n",
    "    print(f\"The model accuracy is {acc_metric.compute() * 100} %.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great, everything works! Let's optimize the entire dataset (this can take up to an hour):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Remember to clear your cache before creating your new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!sudo rm -r /cache/data /cache/imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_optimizer = DatasetOptimizer(\n",
    "    name=\"imagnet/train\",\n",
    "    src_dir=f\"{s3_path}/train\",\n",
    "    fast_dev_run=False,\n",
    "    num_workers=32,\n",
    ")\n",
    "dataset_optimizer.run(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_optimizer = DatasetOptimizer(\n",
    "    name=\"imagenet/val\",\n",
    "    src_dir=f\"{s3_path}/val\",\n",
    "    fast_dev_run=False,\n",
    "    num_workers=32,\n",
    ")\n",
    "dataset_optimizer.run(recipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Multi-GPU on the Cloud\n",
    "\n",
    "## How can multiple GPU's help?\n",
    "Training on the Cloud is expensive. The faster we can train the cheaper it is for us and the more development iterations we can get through in a shorter period of time.\n",
    "\n",
    "- Distributed Data Parallel (DDP) allows to  process batches  in parallel\n",
    "- (Cost of 4xT4) < 4 * (Cost of 1xT4)\n",
    "    - A 4x speed up without paying 4x the price\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from lightning.pytorch.utilities.model_helpers import get_torchvision_model\n",
    "from imagenet_utils import (\n",
    "    get_class_index_from_filepath,\n",
    "    to_rgb,\n",
    "    shuffle,\n",
    "    load_imagenet_val_class_names,\n",
    "    class_names_to_index_map,\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "from lightning import LightningDataModule\n",
    "from lightning.data import StreamingDataset\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageNetLightningModel(LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        arch: str = \"resnet18\",\n",
    "        weights: Optional[str] = None,\n",
    "        lr: float = 0.1,\n",
    "        momentum: float = 0.9,\n",
    "        weight_decay: float = 1e-4,\n",
    "        batch_size: int = 256,\n",
    "        workers: int = 4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.weights = weights\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "        self.model = get_torchvision_model(self.arch, weights=self.weights)\n",
    "        self.train_acc1 = Accuracy(task=\"multiclass\", num_classes=1000, top_k=1)\n",
    "        self.eval_acc1 = Accuracy(task=\"multiclass\", num_classes=1000, top_k=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, target = batch\n",
    "        output = self.model(images)\n",
    "        loss_train = F.cross_entropy(output, target)\n",
    "        self.log(\"train_loss\", loss_train)\n",
    "        # update metrics\n",
    "        self.train_acc1(output, target)\n",
    "        self.log(\"train_acc1\", self.train_acc1, prog_bar=True)\n",
    "        return loss_train\n",
    "\n",
    "    def eval_step(self, batch, batch_idx, prefix: str):\n",
    "        images, target = batch\n",
    "        output = self.model(images)\n",
    "        loss_val = F.cross_entropy(output, target)\n",
    "        self.log(f\"{prefix}_loss\", loss_val)\n",
    "        # update metrics\n",
    "        self.eval_acc1(output, target)\n",
    "        self.log(f\"{prefix}_acc1\", self.eval_acc1, prog_bar=True)\n",
    "        return loss_val\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.eval_step(batch, batch_idx, \"val\")\n",
    "\n",
    "    # def test_step(self, batch, batch_idx):\n",
    "        return self.eval_step(batch, batch_idx, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.1 ** (epoch // 30))\n",
    "        return [optimizer], [scheduler]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ImageNetLightningModel()\n",
    "data_module = ImageNetCloudDataModule()\n",
    "trainer = Trainer(\n",
    "    max_epochs=90,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    logger=False,\n",
    "    callbacks=[\n",
    "        TQDMProgressBar(refresh_rate=10),\n",
    "        ModelCheckpoint(monitor=\"val_acc1\", mode=\"max\"),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
